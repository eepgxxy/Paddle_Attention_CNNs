# Paddle_Attention_CNNs
Some attention boosted CNNs implemented using [PaddlePaddle](https://github.com/paddlePaddle), mainly for classification tasks.

## List of Archtectures

The PaddlePaddle implemented archtectures are: DCANet, ECANet, GCNet, BAT, RAN, SGE, SA, BAM, CBAM, SE, GE and SRM. 

### DCANet

Paper: [DCANet: Learning Connected Attentions for Convolutional Neural Networks, Arxiv 2020](https://arxiv.org/pdf/2007.05099.pdf)
Reference Code: [Pytorch Code](https://github.com/13952522076/DCANet)

### ECANet

Paper: [ECA-Net: Efficient Channel Attention, CVPR 2020](https://arxiv.org/abs/1910.03151)
Reference Code: [Pytorch Code](https://github.com/BangguWu/ECANet)

### Non-local Series

#### GCNet

Paper: [GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond, Arxiv 2019](https://arxiv.org/abs/1904.11492)
Reference Code: [Pytorch Code](https://github.com/xvjiarui/GCNet)

#### BAT

Paper: [Non-Local Neural Networks with Grouped Bilinear Attentional Transforms, CVPR 2020](http://openaccess.thecvf.com/content_CVPR_2020/html/Chi_Non-Local_Neural_Networks_With_Grouped_Bilinear_Attentional_Transforms_CVPR_2020_paper.html)
Reference Code: [Pytorch Code](https://github.com/BA-Transform/BAT-Image-Classification)


### RAN

Paper: [Residual Attention Network for Image Classification, CVPR 2017](https://arxiv.org/pdf/1704.06904.pdf)
Reference Code: [Pytorch Code](https://github.com/tengshaofeng/ResidualAttentionNetwork-pytorch)

### SGE

Paper: [Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks, Arxiv 2019](https://arxiv.org/pdf/1905.09646.pdf)
Reference Code: [Pytorch Code](https://github.com/implus/PytorchInsight)

### SA

Paper: [SA-Net: Shuffle Attention for Deep Convolutional Neural Networks，ICASSP 2021](https://arxiv.org/pdf/2102.00240.pdf)
Reference Code: [Pytorch Code](https://github.com/wofmanaf/SA-Net)

### BAM and CBAM

Paper: [BAM: Bottleneck Attention Module, BMVC 2018](https://arxiv.org/abs/1807.06514)
Paper: [CBAM: Convolutional Block Attention Module， ECCV 2018](https://arxiv.org/pdf/1807.06521.pdf)
Reference Code: [Pytorch Code](https://github.com/Jongchan/attention-module)


### SRM, SE and GE

#### SRM

Paper: [A Style-based Recalibration Module for Convolutional Neural Networks, Arxiv 2019](https://arxiv.org/abs/1903.10829.pdf)
Reference Code: [Pytorch Code](https://github.com/hyunjaelee410/style-based-recalibration-module)

#### SE

Paper: [Squeeze-and-Excitation Networks, CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf)
Reference Code: [Caffe Code](https://github.com/hujie-frank/SENet)

#### GE

Paper: [Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks, NIPS 2018](https://papers.nips.cc/paper/8151-gather-excite-exploiting-feature-context-in-convolutional-neural-networks.pdf)
Reference Code: [Caffe Code](https://github.com/hujie-frank/GENet)

## TBD

More attention boosted CNNs are to be added later.
